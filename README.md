
# ğŸ“„ Resume Matching System (AI-Powered Candidate Filtering)

A scalable, real-world-ready **Resume Matching System** that intelligently parses, filters, and ranks resumes based on job descriptions using **NLP**, **LLMs**, and **semantic embeddings**. Designed for bulk hiring use cases with a modular pipeline structure.

## ğŸ“Œ Key Features

- ğŸ§  **JD parsing using Groqâ€™s LLaMA3 model**
- ğŸ“„ **Resume parsing from `.pdf` and `.docx` files**
- ğŸ”– **Canonical job role tagging (`jobtitle_flag`)**
- ğŸ—ºï¸ **Location-aware filtering: State â†’ Neighboring States â†’ Country**
- ğŸ’¼ **Filtering on `jobtitle_flag` and `job_title`**
- ğŸ“¦ **Result export as structured `.json` files**
- ğŸ” **Embeddings via `intfloat/e5-base` and `JobBERT`**
- ğŸ’½ **PostgreSQL + pgvector backend**
- ğŸš€ **No scoring in filtering step â€” boolean-only for clarity**
- ğŸ§© **Pluggable matching and ranking logic**
- ğŸŒ **Supports Indian and international geographies**

## ğŸ—ƒï¸ Directory Structure

```
ResumeMatching/
â”‚
â”œâ”€â”€ resumeExtractor.py         # Resume metadata extractor
â”œâ”€â”€ jd_dataExtractor.py        # JD metadata extractor (via Groq)
â”œâ”€â”€ filterMatcher.py           # Filtering logic using job title, location
â”œâ”€â”€ saveFiltered.py            # Save filtered results as JSON
â”œâ”€â”€ match_driver.py            # Entry point for matching pipeline
â”œâ”€â”€ jobbert_matcher.py         # Embedding-based job title matcher
â”œâ”€â”€ Neighbours.py              # Country-wise state â†’ neighbors dictionary
â”‚
â”œâ”€â”€ resumes/                   # Raw resume uploads
â”œâ”€â”€ results/                   # Output JSON files
â”œâ”€â”€ jd_samples/                # JD text files for testing
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ§  Pipeline Overview

### Step 1ï¸âƒ£: Resume Metadata Extraction (One-Time)
- Extract name, job title, skills, experience, education, country/state
- Clean full resume text (`inline_resume`)
- Auto-classify `jobtitle_flag` using JobBERT
- Embedding vector stored via pgvector

### Step 2ï¸âƒ£: Job Description Parsing (Groq)
- Groq's LLM extracts:
  - `job_title`, `jobtitle_flag`
  - `required_skills`, `required_education`, `required_experience`
  - `state`, `country` (location constraints)

### Step 3ï¸âƒ£: Resume Filtering (Boolean Logic)
- **Phase 1**: Strict match on `state + country`
- **Phase 2**: Neighboring states fallback (via `Neighbours.py`)
- **Phase 3**: Entire country fallback if candidates < threshold
- Filtering requires matching jobtitle flag or job title

### Step 4ï¸âƒ£: Result Saving & Display
- Distinguishes candidates:
  - âœ… Strict Match
  - ğŸŸ¡ Neighbor State Match
  - ğŸŸ  Country Match
- Results saved to `/results/{jd_title}_{timestamp}.json`

## ğŸ“¦ Sample JSON Output

```json
[
  {
    "name": "Rohan Desai",
    "job_title": "Data Scientist",
    "jobtitle_flag": "Data & AI Professional",
    "state": "Maharashtra",
    "country": "India",
    "location_match": false,
    "date_uploaded": "2025-07-15T05:44:45.727177"
  }
]
```

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repo
```bash
git clone https://github.com/yourusername/resume-matching-system.git
cd resume-matching-system
```

### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate        # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3ï¸âƒ£ PostgreSQL Setup
Ensure PostgreSQL is installed and running.

```sql
CREATE DATABASE ResumeDB;

-- Create resume table with vector storage
CREATE EXTENSION IF NOT EXISTS vector;
CREATE TABLE resume (
    id SERIAL PRIMARY KEY,
    name TEXT,
    job_title TEXT,
    jobtitle_flag TEXT,
    skills TEXT,
    experience TEXT,
    education TEXT,
    country TEXT,
    state TEXT,
    upload_date TIMESTAMP,
    inline_resume TEXT,
    embedding VECTOR(768)
);
```

### 4ï¸âƒ£ Set API Key
Set your Groq API key and model in `jd_dataExtractor.py` or `.env`:

```python
GROQ_API_KEY = "your_groq_api_key"
GROQ_MODEL = "llama3-70b-8192"
```

## â–¶ï¸ How to Run

### Match resumes with a JD:

1. Add a JD file (`jd.txt`)
2. Run the driver:

```bash
python match_driver.py
```

It will:
- Extract structured JD
- Find matching resumes
- Print matches
- Save filtered results to `results/` as `.json`

## ğŸ§  Matching Logic Summary

| Phase      | Match Scope        | Priority | Notes                                  |
|------------|--------------------|----------|----------------------------------------|
| Phase 1    | Exact State + Country | âœ… Strict | Direct matches only                    |
| Phase 2    | Neighboring States     | ğŸŸ¡ Soft   | Fallback using country-specific dict   |
| Phase 3    | Entire Country         | ğŸŸ  Softest | Final fallback for broader coverage    |

## ğŸ§± Tech Stack

- **Python 3.10+**
- **PostgreSQL** + `pgvector`
- **Sentence Transformers** (`e5-base`, `JobBERT`)
- **Langchain (optional)** for prompt chaining
- **Groq API** (LLaMA3 models)
- **pdfminer / python-docx** for resume parsing

## ğŸ”® Future Enhancements

- [ ] Ranking engine (cosine similarity + scoring)
- [ ] LangChain + RAG for interactive JD clarification
- [ ] Resume upload UI (Streamlit / Flask)
- [ ] Advanced analytics dashboard
- [ ] Feedback-driven retraining (active learning)

## ğŸ§ª Testing

Use `match_driver.py` to run the entire pipeline on a sample JD.
Ensure resume metadata is pre-extracted and stored in PostgreSQL.

## ğŸ’¡ Contribution Guide

We welcome contributions! If you'd like to:
- Add new JD formats
- Improve metadata extraction
- Extend filtering logic
- Build a frontend

Feel free to fork, open PRs, or raise issues.

## ğŸ“œ License

MIT License. See `LICENSE` for full terms.

## ğŸ‘¨â€ğŸ’» Author

**Dhruv Kumar Agrawal**  
Intern @ InfoOrigin | AI/ML, NLP, LLMs & Systems Design

## â­ Support the Project

If this project helped you, consider giving it a â­ on GitHub and sharing your feedback!
